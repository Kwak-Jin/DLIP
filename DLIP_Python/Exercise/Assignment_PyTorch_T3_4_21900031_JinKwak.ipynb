{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xRZWfUwWQ1f6"
   },
   "source": [
    "# **DLIP Tutorial - PyTorch**\n",
    "# ResNet-50 Model\n",
    "Y.-K. Kim\n",
    "(updated 2024. 5. 14) \n",
    "\n",
    "Jin Kwak/ 21900031\n",
    "(edited 24. 05. 24)\n",
    "\n",
    "The purpose of this tutorial is to make ResNet 50 model\n",
    "\n",
    "https://arxiv.org/pdf/1512.03385\n",
    "\n",
    "## For CoLab Usage:\n",
    "\n",
    "1. Download this notebook\n",
    "2. Then, open in Colab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xab0AzXTQ62Y"
   },
   "source": [
    "# Setup Pytorch and Numpy and Device\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "a9hU4TNgQzAu",
    "ExecuteTime": {
     "end_time": "2024-05-24T02:18:36.507957Z",
     "start_time": "2024-05-24T02:18:34.010668Z"
    }
   },
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fSlpzBkbSWn9",
    "outputId": "d7884142-101b-4d55-877a-513b1d8b4fb1",
    "ExecuteTime": {
     "end_time": "2024-05-24T02:18:36.647349Z",
     "start_time": "2024-05-24T02:18:36.508917Z"
    }
   },
   "source": [
    "# Get cpu or gpu device for training.\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "print(f\"Using {device} device\")\n",
    "if torch.cuda.is_available(): print(f'Device name: {torch.cuda.get_device_name(0)}') "
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n",
      "Device name: NVIDIA GeForce RTX 4060 Laptop GPU\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "85aC7eEvRD2q"
   },
   "source": [
    "# Prepare Datasets: Input and Output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AIAX4YhwSzac"
   },
   "source": [
    "We will not use dataset for training.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HS-4blG6Ugc5"
   },
   "source": [
    "# (Assignment) Define model - ResNet 50\n",
    "\n",
    "create a class that inherits from nn.Module\n",
    "\n",
    "\n",
    "* Define the layers of the network in  __init__ function\n",
    "* Specify Forward network in the **forward function.**\n",
    "* Activate Function: `ReLU`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IdIlH3E2eRs7"
   },
   "source": [
    "\n",
    "![ResNet50_architecture](https://github.com/ykkimhgu/DLIP-src/assets/84508106/7bcd1af8-20b8-49f6-85f2-b29bf612286b)\n",
    "\n",
    "![image](https://github.com/ykkimhgu/DLIP-src/assets/84508106/c4a7350c-cfc9-4bdb-8864-e741f28fea12)\n",
    "\n",
    "#### Skip Connection\n",
    "![image](https://github.com/ykkimhgu/DLIP-src/assets/84508106/425af944-dc82-4d8b-b9a9-b7c0344b8e0f)\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-24T02:47:33.114667Z",
     "start_time": "2024-05-24T02:47:32.863756Z"
    }
   },
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# BasicBlock class defines the building block for ResNet\n",
    "class BasicBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, down_sampling=None, stride=1):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.expansion = 4  # Expansion ratio for ResNet-50, 101, 152\n",
    "        self.down_sampling = down_sampling\n",
    "        self.stride = stride\n",
    "        self.flatten= nn.Flatten()\n",
    "        \n",
    "        self.ReLU = nn.ReLU(inplace=True)\n",
    "        self.conv_layer1 = nn.Conv2d(in_channels , out_channels, kernel_size=1  , stride=stride, padding=0, bias=False)\n",
    "        self.batch_norm1 = nn.BatchNorm2d(out_channels)\n",
    "        \n",
    "        \n",
    "        self.conv_layer2 = nn.Conv2d(out_channels, out_channels, kernel_size=3  , stride=1, padding=1, bias=False)\n",
    "        self.batch_norm2 = nn.BatchNorm2d(out_channels)\n",
    "\n",
    "        self.conv_layer3 = nn.Conv2d(out_channels, out_channels * self.expansion, kernel_size=1, stride=1, padding=0, bias=False)\n",
    "        self.batch_norm3 = nn.BatchNorm2d(out_channels*self.expansion)  #Channels 64--> 256, 128 --> 512, 256 --> 1024\n",
    "        \n",
    "        if down_sampling:\n",
    "            self.down_sampling = nn.Sequential(\n",
    "                nn.Conv2d(in_channels, out_channels*self.expansion, kernel_size=1, stride=stride, padding=0, bias=False),\n",
    "                nn.BatchNorm2d(out_channels*self.expansion)                                                                 \n",
    "            )\n",
    "        # else self.downsampling is predefined as None!\n",
    "        \n",
    "    def forward(self, x:torch.Tensor) -> torch.Tensor:\n",
    "        # For Feedforward \n",
    "        identity = x.clone()\n",
    "        \n",
    "        out = self.conv_layer1(x)\n",
    "        out = self.batch_norm1(out)\n",
    "        out = self.ReLU(out)\n",
    "\n",
    "        out = self.conv_layer2(out)\n",
    "        out = self.batch_norm2(out)\n",
    "\n",
    "        out = self.conv_layer3(out)\n",
    "        out = self.batch_norm3(out)\n",
    "        \n",
    "        \n",
    "        # Layer Change\n",
    "        if self.down_sampling:      # Skip Connect\n",
    "            identity = self.down_sampling(identity)\n",
    "        \n",
    "        out += identity\n",
    "        out = self.ReLU(out)\n",
    "        \n",
    "        return out\n",
    "\n",
    "# ResNet class defines the entire ResNet-50 architecture\n",
    "\"\"\"\n",
    "ResNet model\n",
    "@Parameter:\n",
    "1. block :(dtype)Class BasicBlock\n",
    "2. layers:(dtype)List  Number of Iterations(?) per layer\n",
    "3. image_channels:(dtype) Int Number of channels of input image\n",
    "4. num_classes:(dtype) Int Number of classification classes\n",
    "\"\"\"\n",
    "class ResNet(nn.Module):\n",
    "    def __init__(self, block, layers, image_channels, num_classes):\n",
    "        super(ResNet, self).__init__()\n",
    "        self.in_channels = 64  # Initial input channels\n",
    "        self.expansion   = 4   # Expansion ratio for ResNet-50, 101, 152\n",
    "        \n",
    "        # conv2d, batch_norm2d, relu, maxpool2d\n",
    "        self.conv = nn.Conv2d(image_channels,self.in_channels, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "        self.batch_norm = nn.BatchNorm2d(self.in_channels)\n",
    "        self.ReLU = nn.ReLU(inplace=True)\n",
    "        self.max_pool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        \n",
    "        # The main layers of ResNet (using self._make_layer)\n",
    "        self.layer1 = self._make_layer(block, layers[0], 64  ,stride=1)\n",
    "        self.layer2 = self._make_layer(block, layers[1], 128 ,stride=2)\n",
    "        self.layer3 = self._make_layer(block, layers[2], 256 ,stride=2)\n",
    "        self.layer4 = self._make_layer(block, layers[3], 512 ,stride=2)\n",
    "\n",
    "        # Adaptive average pooling\n",
    "        self.avg_pool = nn.AdaptiveAvgPool2d((1,1)) \n",
    "        \n",
    "        # Fully connected layer\n",
    "        self.fc = nn.Linear(512 * self.expansion, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # First conv layer -> bn -> relu -> maxpooling\n",
    "        x = self.conv(x)\n",
    "        x = self.batch_norm(x)\n",
    "        x = self.ReLU(x)\n",
    "        x = self.max_pool(x)\n",
    "        \n",
    "        # Layer 1 ~ 4\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "        \n",
    "        # Adaptive average pooling\n",
    "        x = self.avg_pool(x)\n",
    "\n",
    "        # Flatten\n",
    "        x = torch.flatten(x, 1)\n",
    "\n",
    "        # Fully connected layer\n",
    "        x = self.fc(x)       \n",
    "            \n",
    "        return x\n",
    "\n",
    "    # _make_layer method constructs the layers for ResNet\n",
    "    def _make_layer(self, block, num_residual_blocks, out_channels, stride):\n",
    "        down_sampling = None\n",
    "        layers = []\n",
    "\n",
    "        # Downsample identity if we change input dimensions or channels\n",
    "        if stride != 1 or self.in_channels != out_channels * self.expansion:\n",
    "            down_sampling = nn.Sequential(\n",
    "            nn.Conv2d(self.in_channels, out_channels * self.expansion, kernel_size=1, stride=stride, bias=False),\n",
    "            nn.BatchNorm2d(out_channels * self.expansion)\n",
    "            )\n",
    "            \n",
    "        # append block layers\n",
    "        layers.append(block(self.in_channels, out_channels, down_sampling, stride))\n",
    "        \n",
    "        # Expansion size is always 4 for ResNet-50, 101, 152 (e.g. 64 -> 256)\n",
    "        self.in_channels = out_channels * self.expansion\n",
    "\n",
    "\n",
    "        # Add additional blocks\n",
    "        for idx in range(1, num_residual_blocks):\n",
    "            layers.append(block(self.in_channels, out_channels))\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "# Function to create ResNet-50 model\n",
    "def ResNet50(img_channel=3, num_classes=1000):\n",
    "    return ResNet(BasicBlock, [3, 4, 6, 3], img_channel, num_classes)\n",
    "\n",
    "model = ResNet50()\n",
    "model = model.cuda()  # Move model to GPU\n",
    "print(model)\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet(\n",
      "  (conv): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "  (batch_norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (ReLU): ReLU(inplace=True)\n",
      "  (max_pool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (down_sampling): Sequential(\n",
      "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "      (ReLU): ReLU(inplace=True)\n",
      "      (conv_layer1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (batch_norm1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv_layer2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (batch_norm2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv_layer3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (batch_norm3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "      (ReLU): ReLU(inplace=True)\n",
      "      (conv_layer1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (batch_norm1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv_layer2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (batch_norm2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv_layer3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (batch_norm3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (2): BasicBlock(\n",
      "      (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "      (ReLU): ReLU(inplace=True)\n",
      "      (conv_layer1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (batch_norm1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv_layer2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (batch_norm2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv_layer3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (batch_norm3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (down_sampling): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "      (ReLU): ReLU(inplace=True)\n",
      "      (conv_layer1): Conv2d(256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "      (batch_norm1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv_layer2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (batch_norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv_layer3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (batch_norm3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "      (ReLU): ReLU(inplace=True)\n",
      "      (conv_layer1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (batch_norm1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv_layer2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (batch_norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv_layer3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (batch_norm3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (2): BasicBlock(\n",
      "      (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "      (ReLU): ReLU(inplace=True)\n",
      "      (conv_layer1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (batch_norm1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv_layer2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (batch_norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv_layer3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (batch_norm3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (3): BasicBlock(\n",
      "      (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "      (ReLU): ReLU(inplace=True)\n",
      "      (conv_layer1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (batch_norm1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv_layer2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (batch_norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv_layer3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (batch_norm3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (down_sampling): Sequential(\n",
      "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "      (ReLU): ReLU(inplace=True)\n",
      "      (conv_layer1): Conv2d(512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "      (batch_norm1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv_layer2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (batch_norm2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv_layer3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (batch_norm3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "      (ReLU): ReLU(inplace=True)\n",
      "      (conv_layer1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (batch_norm1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv_layer2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (batch_norm2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv_layer3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (batch_norm3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (2): BasicBlock(\n",
      "      (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "      (ReLU): ReLU(inplace=True)\n",
      "      (conv_layer1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (batch_norm1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv_layer2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (batch_norm2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv_layer3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (batch_norm3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (3): BasicBlock(\n",
      "      (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "      (ReLU): ReLU(inplace=True)\n",
      "      (conv_layer1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (batch_norm1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv_layer2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (batch_norm2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv_layer3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (batch_norm3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (4): BasicBlock(\n",
      "      (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "      (ReLU): ReLU(inplace=True)\n",
      "      (conv_layer1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (batch_norm1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv_layer2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (batch_norm2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv_layer3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (batch_norm3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (5): BasicBlock(\n",
      "      (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "      (ReLU): ReLU(inplace=True)\n",
      "      (conv_layer1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (batch_norm1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv_layer2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (batch_norm2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv_layer3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (batch_norm3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (down_sampling): Sequential(\n",
      "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "      (ReLU): ReLU(inplace=True)\n",
      "      (conv_layer1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "      (batch_norm1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv_layer2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (batch_norm2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv_layer3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (batch_norm3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "      (ReLU): ReLU(inplace=True)\n",
      "      (conv_layer1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (batch_norm1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv_layer2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (batch_norm2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv_layer3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (batch_norm3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (2): BasicBlock(\n",
      "      (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "      (ReLU): ReLU(inplace=True)\n",
      "      (conv_layer1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (batch_norm1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv_layer2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (batch_norm2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv_layer3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (batch_norm3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (avg_pool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): Linear(in_features=2048, out_features=1000, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7SPvx776gUcj"
   },
   "source": [
    "Check your model is valid by **summary()** function\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "KcNiG096gUAz",
    "ExecuteTime": {
     "end_time": "2024-05-24T02:47:36.297454Z",
     "start_time": "2024-05-24T02:47:35.655205Z"
    }
   },
   "source": [
    "from torchsummary import summary\n",
    "import torchvision.models as models\n",
    "model_resnet50 = models.resnet50(pretrained=True).cuda()\n",
    "\n",
    "summary(model_resnet50, (3,224,224))\n",
    "summary(model, (3, 224, 224))\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 64, 112, 112]           9,408\n",
      "       BatchNorm2d-2         [-1, 64, 112, 112]             128\n",
      "              ReLU-3         [-1, 64, 112, 112]               0\n",
      "         MaxPool2d-4           [-1, 64, 56, 56]               0\n",
      "            Conv2d-5           [-1, 64, 56, 56]           4,096\n",
      "       BatchNorm2d-6           [-1, 64, 56, 56]             128\n",
      "              ReLU-7           [-1, 64, 56, 56]               0\n",
      "            Conv2d-8           [-1, 64, 56, 56]          36,864\n",
      "       BatchNorm2d-9           [-1, 64, 56, 56]             128\n",
      "             ReLU-10           [-1, 64, 56, 56]               0\n",
      "           Conv2d-11          [-1, 256, 56, 56]          16,384\n",
      "      BatchNorm2d-12          [-1, 256, 56, 56]             512\n",
      "           Conv2d-13          [-1, 256, 56, 56]          16,384\n",
      "      BatchNorm2d-14          [-1, 256, 56, 56]             512\n",
      "             ReLU-15          [-1, 256, 56, 56]               0\n",
      "       Bottleneck-16          [-1, 256, 56, 56]               0\n",
      "           Conv2d-17           [-1, 64, 56, 56]          16,384\n",
      "      BatchNorm2d-18           [-1, 64, 56, 56]             128\n",
      "             ReLU-19           [-1, 64, 56, 56]               0\n",
      "           Conv2d-20           [-1, 64, 56, 56]          36,864\n",
      "      BatchNorm2d-21           [-1, 64, 56, 56]             128\n",
      "             ReLU-22           [-1, 64, 56, 56]               0\n",
      "           Conv2d-23          [-1, 256, 56, 56]          16,384\n",
      "      BatchNorm2d-24          [-1, 256, 56, 56]             512\n",
      "             ReLU-25          [-1, 256, 56, 56]               0\n",
      "       Bottleneck-26          [-1, 256, 56, 56]               0\n",
      "           Conv2d-27           [-1, 64, 56, 56]          16,384\n",
      "      BatchNorm2d-28           [-1, 64, 56, 56]             128\n",
      "             ReLU-29           [-1, 64, 56, 56]               0\n",
      "           Conv2d-30           [-1, 64, 56, 56]          36,864\n",
      "      BatchNorm2d-31           [-1, 64, 56, 56]             128\n",
      "             ReLU-32           [-1, 64, 56, 56]               0\n",
      "           Conv2d-33          [-1, 256, 56, 56]          16,384\n",
      "      BatchNorm2d-34          [-1, 256, 56, 56]             512\n",
      "             ReLU-35          [-1, 256, 56, 56]               0\n",
      "       Bottleneck-36          [-1, 256, 56, 56]               0\n",
      "           Conv2d-37          [-1, 128, 56, 56]          32,768\n",
      "      BatchNorm2d-38          [-1, 128, 56, 56]             256\n",
      "             ReLU-39          [-1, 128, 56, 56]               0\n",
      "           Conv2d-40          [-1, 128, 28, 28]         147,456\n",
      "      BatchNorm2d-41          [-1, 128, 28, 28]             256\n",
      "             ReLU-42          [-1, 128, 28, 28]               0\n",
      "           Conv2d-43          [-1, 512, 28, 28]          65,536\n",
      "      BatchNorm2d-44          [-1, 512, 28, 28]           1,024\n",
      "           Conv2d-45          [-1, 512, 28, 28]         131,072\n",
      "      BatchNorm2d-46          [-1, 512, 28, 28]           1,024\n",
      "             ReLU-47          [-1, 512, 28, 28]               0\n",
      "       Bottleneck-48          [-1, 512, 28, 28]               0\n",
      "           Conv2d-49          [-1, 128, 28, 28]          65,536\n",
      "      BatchNorm2d-50          [-1, 128, 28, 28]             256\n",
      "             ReLU-51          [-1, 128, 28, 28]               0\n",
      "           Conv2d-52          [-1, 128, 28, 28]         147,456\n",
      "      BatchNorm2d-53          [-1, 128, 28, 28]             256\n",
      "             ReLU-54          [-1, 128, 28, 28]               0\n",
      "           Conv2d-55          [-1, 512, 28, 28]          65,536\n",
      "      BatchNorm2d-56          [-1, 512, 28, 28]           1,024\n",
      "             ReLU-57          [-1, 512, 28, 28]               0\n",
      "       Bottleneck-58          [-1, 512, 28, 28]               0\n",
      "           Conv2d-59          [-1, 128, 28, 28]          65,536\n",
      "      BatchNorm2d-60          [-1, 128, 28, 28]             256\n",
      "             ReLU-61          [-1, 128, 28, 28]               0\n",
      "           Conv2d-62          [-1, 128, 28, 28]         147,456\n",
      "      BatchNorm2d-63          [-1, 128, 28, 28]             256\n",
      "             ReLU-64          [-1, 128, 28, 28]               0\n",
      "           Conv2d-65          [-1, 512, 28, 28]          65,536\n",
      "      BatchNorm2d-66          [-1, 512, 28, 28]           1,024\n",
      "             ReLU-67          [-1, 512, 28, 28]               0\n",
      "       Bottleneck-68          [-1, 512, 28, 28]               0\n",
      "           Conv2d-69          [-1, 128, 28, 28]          65,536\n",
      "      BatchNorm2d-70          [-1, 128, 28, 28]             256\n",
      "             ReLU-71          [-1, 128, 28, 28]               0\n",
      "           Conv2d-72          [-1, 128, 28, 28]         147,456\n",
      "      BatchNorm2d-73          [-1, 128, 28, 28]             256\n",
      "             ReLU-74          [-1, 128, 28, 28]               0\n",
      "           Conv2d-75          [-1, 512, 28, 28]          65,536\n",
      "      BatchNorm2d-76          [-1, 512, 28, 28]           1,024\n",
      "             ReLU-77          [-1, 512, 28, 28]               0\n",
      "       Bottleneck-78          [-1, 512, 28, 28]               0\n",
      "           Conv2d-79          [-1, 256, 28, 28]         131,072\n",
      "      BatchNorm2d-80          [-1, 256, 28, 28]             512\n",
      "             ReLU-81          [-1, 256, 28, 28]               0\n",
      "           Conv2d-82          [-1, 256, 14, 14]         589,824\n",
      "      BatchNorm2d-83          [-1, 256, 14, 14]             512\n",
      "             ReLU-84          [-1, 256, 14, 14]               0\n",
      "           Conv2d-85         [-1, 1024, 14, 14]         262,144\n",
      "      BatchNorm2d-86         [-1, 1024, 14, 14]           2,048\n",
      "           Conv2d-87         [-1, 1024, 14, 14]         524,288\n",
      "      BatchNorm2d-88         [-1, 1024, 14, 14]           2,048\n",
      "             ReLU-89         [-1, 1024, 14, 14]               0\n",
      "       Bottleneck-90         [-1, 1024, 14, 14]               0\n",
      "           Conv2d-91          [-1, 256, 14, 14]         262,144\n",
      "      BatchNorm2d-92          [-1, 256, 14, 14]             512\n",
      "             ReLU-93          [-1, 256, 14, 14]               0\n",
      "           Conv2d-94          [-1, 256, 14, 14]         589,824\n",
      "      BatchNorm2d-95          [-1, 256, 14, 14]             512\n",
      "             ReLU-96          [-1, 256, 14, 14]               0\n",
      "           Conv2d-97         [-1, 1024, 14, 14]         262,144\n",
      "      BatchNorm2d-98         [-1, 1024, 14, 14]           2,048\n",
      "             ReLU-99         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-100         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-101          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-102          [-1, 256, 14, 14]             512\n",
      "            ReLU-103          [-1, 256, 14, 14]               0\n",
      "          Conv2d-104          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-105          [-1, 256, 14, 14]             512\n",
      "            ReLU-106          [-1, 256, 14, 14]               0\n",
      "          Conv2d-107         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-108         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-109         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-110         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-111          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-112          [-1, 256, 14, 14]             512\n",
      "            ReLU-113          [-1, 256, 14, 14]               0\n",
      "          Conv2d-114          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-115          [-1, 256, 14, 14]             512\n",
      "            ReLU-116          [-1, 256, 14, 14]               0\n",
      "          Conv2d-117         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-118         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-119         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-120         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-121          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-122          [-1, 256, 14, 14]             512\n",
      "            ReLU-123          [-1, 256, 14, 14]               0\n",
      "          Conv2d-124          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-125          [-1, 256, 14, 14]             512\n",
      "            ReLU-126          [-1, 256, 14, 14]               0\n",
      "          Conv2d-127         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-128         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-129         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-130         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-131          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-132          [-1, 256, 14, 14]             512\n",
      "            ReLU-133          [-1, 256, 14, 14]               0\n",
      "          Conv2d-134          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-135          [-1, 256, 14, 14]             512\n",
      "            ReLU-136          [-1, 256, 14, 14]               0\n",
      "          Conv2d-137         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-138         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-139         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-140         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-141          [-1, 512, 14, 14]         524,288\n",
      "     BatchNorm2d-142          [-1, 512, 14, 14]           1,024\n",
      "            ReLU-143          [-1, 512, 14, 14]               0\n",
      "          Conv2d-144            [-1, 512, 7, 7]       2,359,296\n",
      "     BatchNorm2d-145            [-1, 512, 7, 7]           1,024\n",
      "            ReLU-146            [-1, 512, 7, 7]               0\n",
      "          Conv2d-147           [-1, 2048, 7, 7]       1,048,576\n",
      "     BatchNorm2d-148           [-1, 2048, 7, 7]           4,096\n",
      "          Conv2d-149           [-1, 2048, 7, 7]       2,097,152\n",
      "     BatchNorm2d-150           [-1, 2048, 7, 7]           4,096\n",
      "            ReLU-151           [-1, 2048, 7, 7]               0\n",
      "      Bottleneck-152           [-1, 2048, 7, 7]               0\n",
      "          Conv2d-153            [-1, 512, 7, 7]       1,048,576\n",
      "     BatchNorm2d-154            [-1, 512, 7, 7]           1,024\n",
      "            ReLU-155            [-1, 512, 7, 7]               0\n",
      "          Conv2d-156            [-1, 512, 7, 7]       2,359,296\n",
      "     BatchNorm2d-157            [-1, 512, 7, 7]           1,024\n",
      "            ReLU-158            [-1, 512, 7, 7]               0\n",
      "          Conv2d-159           [-1, 2048, 7, 7]       1,048,576\n",
      "     BatchNorm2d-160           [-1, 2048, 7, 7]           4,096\n",
      "            ReLU-161           [-1, 2048, 7, 7]               0\n",
      "      Bottleneck-162           [-1, 2048, 7, 7]               0\n",
      "          Conv2d-163            [-1, 512, 7, 7]       1,048,576\n",
      "     BatchNorm2d-164            [-1, 512, 7, 7]           1,024\n",
      "            ReLU-165            [-1, 512, 7, 7]               0\n",
      "          Conv2d-166            [-1, 512, 7, 7]       2,359,296\n",
      "     BatchNorm2d-167            [-1, 512, 7, 7]           1,024\n",
      "            ReLU-168            [-1, 512, 7, 7]               0\n",
      "          Conv2d-169           [-1, 2048, 7, 7]       1,048,576\n",
      "     BatchNorm2d-170           [-1, 2048, 7, 7]           4,096\n",
      "            ReLU-171           [-1, 2048, 7, 7]               0\n",
      "      Bottleneck-172           [-1, 2048, 7, 7]               0\n",
      "AdaptiveAvgPool2d-173           [-1, 2048, 1, 1]               0\n",
      "          Linear-174                 [-1, 1000]       2,049,000\n",
      "================================================================\n",
      "Total params: 25,557,032\n",
      "Trainable params: 25,557,032\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.57\n",
      "Forward/backward pass size (MB): 286.56\n",
      "Params size (MB): 97.49\n",
      "Estimated Total Size (MB): 384.62\n",
      "----------------------------------------------------------------\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 64, 112, 112]           9,408\n",
      "       BatchNorm2d-2         [-1, 64, 112, 112]             128\n",
      "              ReLU-3         [-1, 64, 112, 112]               0\n",
      "         MaxPool2d-4           [-1, 64, 56, 56]               0\n",
      "            Conv2d-5           [-1, 64, 56, 56]           4,096\n",
      "       BatchNorm2d-6           [-1, 64, 56, 56]             128\n",
      "              ReLU-7           [-1, 64, 56, 56]               0\n",
      "            Conv2d-8           [-1, 64, 56, 56]          36,864\n",
      "       BatchNorm2d-9           [-1, 64, 56, 56]             128\n",
      "           Conv2d-10          [-1, 256, 56, 56]          16,384\n",
      "      BatchNorm2d-11          [-1, 256, 56, 56]             512\n",
      "           Conv2d-12          [-1, 256, 56, 56]          16,384\n",
      "      BatchNorm2d-13          [-1, 256, 56, 56]             512\n",
      "             ReLU-14          [-1, 256, 56, 56]               0\n",
      "       BasicBlock-15          [-1, 256, 56, 56]               0\n",
      "           Conv2d-16           [-1, 64, 56, 56]          16,384\n",
      "      BatchNorm2d-17           [-1, 64, 56, 56]             128\n",
      "             ReLU-18           [-1, 64, 56, 56]               0\n",
      "           Conv2d-19           [-1, 64, 56, 56]          36,864\n",
      "      BatchNorm2d-20           [-1, 64, 56, 56]             128\n",
      "           Conv2d-21          [-1, 256, 56, 56]          16,384\n",
      "      BatchNorm2d-22          [-1, 256, 56, 56]             512\n",
      "             ReLU-23          [-1, 256, 56, 56]               0\n",
      "       BasicBlock-24          [-1, 256, 56, 56]               0\n",
      "           Conv2d-25           [-1, 64, 56, 56]          16,384\n",
      "      BatchNorm2d-26           [-1, 64, 56, 56]             128\n",
      "             ReLU-27           [-1, 64, 56, 56]               0\n",
      "           Conv2d-28           [-1, 64, 56, 56]          36,864\n",
      "      BatchNorm2d-29           [-1, 64, 56, 56]             128\n",
      "           Conv2d-30          [-1, 256, 56, 56]          16,384\n",
      "      BatchNorm2d-31          [-1, 256, 56, 56]             512\n",
      "             ReLU-32          [-1, 256, 56, 56]               0\n",
      "       BasicBlock-33          [-1, 256, 56, 56]               0\n",
      "           Conv2d-34          [-1, 128, 28, 28]          32,768\n",
      "      BatchNorm2d-35          [-1, 128, 28, 28]             256\n",
      "             ReLU-36          [-1, 128, 28, 28]               0\n",
      "           Conv2d-37          [-1, 128, 28, 28]         147,456\n",
      "      BatchNorm2d-38          [-1, 128, 28, 28]             256\n",
      "           Conv2d-39          [-1, 512, 28, 28]          65,536\n",
      "      BatchNorm2d-40          [-1, 512, 28, 28]           1,024\n",
      "           Conv2d-41          [-1, 512, 28, 28]         131,072\n",
      "      BatchNorm2d-42          [-1, 512, 28, 28]           1,024\n",
      "             ReLU-43          [-1, 512, 28, 28]               0\n",
      "       BasicBlock-44          [-1, 512, 28, 28]               0\n",
      "           Conv2d-45          [-1, 128, 28, 28]          65,536\n",
      "      BatchNorm2d-46          [-1, 128, 28, 28]             256\n",
      "             ReLU-47          [-1, 128, 28, 28]               0\n",
      "           Conv2d-48          [-1, 128, 28, 28]         147,456\n",
      "      BatchNorm2d-49          [-1, 128, 28, 28]             256\n",
      "           Conv2d-50          [-1, 512, 28, 28]          65,536\n",
      "      BatchNorm2d-51          [-1, 512, 28, 28]           1,024\n",
      "             ReLU-52          [-1, 512, 28, 28]               0\n",
      "       BasicBlock-53          [-1, 512, 28, 28]               0\n",
      "           Conv2d-54          [-1, 128, 28, 28]          65,536\n",
      "      BatchNorm2d-55          [-1, 128, 28, 28]             256\n",
      "             ReLU-56          [-1, 128, 28, 28]               0\n",
      "           Conv2d-57          [-1, 128, 28, 28]         147,456\n",
      "      BatchNorm2d-58          [-1, 128, 28, 28]             256\n",
      "           Conv2d-59          [-1, 512, 28, 28]          65,536\n",
      "      BatchNorm2d-60          [-1, 512, 28, 28]           1,024\n",
      "             ReLU-61          [-1, 512, 28, 28]               0\n",
      "       BasicBlock-62          [-1, 512, 28, 28]               0\n",
      "           Conv2d-63          [-1, 128, 28, 28]          65,536\n",
      "      BatchNorm2d-64          [-1, 128, 28, 28]             256\n",
      "             ReLU-65          [-1, 128, 28, 28]               0\n",
      "           Conv2d-66          [-1, 128, 28, 28]         147,456\n",
      "      BatchNorm2d-67          [-1, 128, 28, 28]             256\n",
      "           Conv2d-68          [-1, 512, 28, 28]          65,536\n",
      "      BatchNorm2d-69          [-1, 512, 28, 28]           1,024\n",
      "             ReLU-70          [-1, 512, 28, 28]               0\n",
      "       BasicBlock-71          [-1, 512, 28, 28]               0\n",
      "           Conv2d-72          [-1, 256, 14, 14]         131,072\n",
      "      BatchNorm2d-73          [-1, 256, 14, 14]             512\n",
      "             ReLU-74          [-1, 256, 14, 14]               0\n",
      "           Conv2d-75          [-1, 256, 14, 14]         589,824\n",
      "      BatchNorm2d-76          [-1, 256, 14, 14]             512\n",
      "           Conv2d-77         [-1, 1024, 14, 14]         262,144\n",
      "      BatchNorm2d-78         [-1, 1024, 14, 14]           2,048\n",
      "           Conv2d-79         [-1, 1024, 14, 14]         524,288\n",
      "      BatchNorm2d-80         [-1, 1024, 14, 14]           2,048\n",
      "             ReLU-81         [-1, 1024, 14, 14]               0\n",
      "       BasicBlock-82         [-1, 1024, 14, 14]               0\n",
      "           Conv2d-83          [-1, 256, 14, 14]         262,144\n",
      "      BatchNorm2d-84          [-1, 256, 14, 14]             512\n",
      "             ReLU-85          [-1, 256, 14, 14]               0\n",
      "           Conv2d-86          [-1, 256, 14, 14]         589,824\n",
      "      BatchNorm2d-87          [-1, 256, 14, 14]             512\n",
      "           Conv2d-88         [-1, 1024, 14, 14]         262,144\n",
      "      BatchNorm2d-89         [-1, 1024, 14, 14]           2,048\n",
      "             ReLU-90         [-1, 1024, 14, 14]               0\n",
      "       BasicBlock-91         [-1, 1024, 14, 14]               0\n",
      "           Conv2d-92          [-1, 256, 14, 14]         262,144\n",
      "      BatchNorm2d-93          [-1, 256, 14, 14]             512\n",
      "             ReLU-94          [-1, 256, 14, 14]               0\n",
      "           Conv2d-95          [-1, 256, 14, 14]         589,824\n",
      "      BatchNorm2d-96          [-1, 256, 14, 14]             512\n",
      "           Conv2d-97         [-1, 1024, 14, 14]         262,144\n",
      "      BatchNorm2d-98         [-1, 1024, 14, 14]           2,048\n",
      "             ReLU-99         [-1, 1024, 14, 14]               0\n",
      "      BasicBlock-100         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-101          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-102          [-1, 256, 14, 14]             512\n",
      "            ReLU-103          [-1, 256, 14, 14]               0\n",
      "          Conv2d-104          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-105          [-1, 256, 14, 14]             512\n",
      "          Conv2d-106         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-107         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-108         [-1, 1024, 14, 14]               0\n",
      "      BasicBlock-109         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-110          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-111          [-1, 256, 14, 14]             512\n",
      "            ReLU-112          [-1, 256, 14, 14]               0\n",
      "          Conv2d-113          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-114          [-1, 256, 14, 14]             512\n",
      "          Conv2d-115         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-116         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-117         [-1, 1024, 14, 14]               0\n",
      "      BasicBlock-118         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-119          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-120          [-1, 256, 14, 14]             512\n",
      "            ReLU-121          [-1, 256, 14, 14]               0\n",
      "          Conv2d-122          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-123          [-1, 256, 14, 14]             512\n",
      "          Conv2d-124         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-125         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-126         [-1, 1024, 14, 14]               0\n",
      "      BasicBlock-127         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-128            [-1, 512, 7, 7]         524,288\n",
      "     BatchNorm2d-129            [-1, 512, 7, 7]           1,024\n",
      "            ReLU-130            [-1, 512, 7, 7]               0\n",
      "          Conv2d-131            [-1, 512, 7, 7]       2,359,296\n",
      "     BatchNorm2d-132            [-1, 512, 7, 7]           1,024\n",
      "          Conv2d-133           [-1, 2048, 7, 7]       1,048,576\n",
      "     BatchNorm2d-134           [-1, 2048, 7, 7]           4,096\n",
      "          Conv2d-135           [-1, 2048, 7, 7]       2,097,152\n",
      "     BatchNorm2d-136           [-1, 2048, 7, 7]           4,096\n",
      "            ReLU-137           [-1, 2048, 7, 7]               0\n",
      "      BasicBlock-138           [-1, 2048, 7, 7]               0\n",
      "          Conv2d-139            [-1, 512, 7, 7]       1,048,576\n",
      "     BatchNorm2d-140            [-1, 512, 7, 7]           1,024\n",
      "            ReLU-141            [-1, 512, 7, 7]               0\n",
      "          Conv2d-142            [-1, 512, 7, 7]       2,359,296\n",
      "     BatchNorm2d-143            [-1, 512, 7, 7]           1,024\n",
      "          Conv2d-144           [-1, 2048, 7, 7]       1,048,576\n",
      "     BatchNorm2d-145           [-1, 2048, 7, 7]           4,096\n",
      "            ReLU-146           [-1, 2048, 7, 7]               0\n",
      "      BasicBlock-147           [-1, 2048, 7, 7]               0\n",
      "          Conv2d-148            [-1, 512, 7, 7]       1,048,576\n",
      "     BatchNorm2d-149            [-1, 512, 7, 7]           1,024\n",
      "            ReLU-150            [-1, 512, 7, 7]               0\n",
      "          Conv2d-151            [-1, 512, 7, 7]       2,359,296\n",
      "     BatchNorm2d-152            [-1, 512, 7, 7]           1,024\n",
      "          Conv2d-153           [-1, 2048, 7, 7]       1,048,576\n",
      "     BatchNorm2d-154           [-1, 2048, 7, 7]           4,096\n",
      "            ReLU-155           [-1, 2048, 7, 7]               0\n",
      "      BasicBlock-156           [-1, 2048, 7, 7]               0\n",
      "AdaptiveAvgPool2d-157           [-1, 2048, 1, 1]               0\n",
      "          Linear-158                 [-1, 1000]       2,049,000\n",
      "================================================================\n",
      "Total params: 25,557,032\n",
      "Trainable params: 25,557,032\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.57\n",
      "Forward/backward pass size (MB): 263.97\n",
      "Params size (MB): 97.49\n",
      "Estimated Total Size (MB): 362.04\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "Tutorial_PyTorch_VGG16_CNN_Part3_1.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
